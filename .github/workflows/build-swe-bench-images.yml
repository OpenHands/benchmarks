name: Build SWE-Bench Images

on:
  pull_request_target:
    types: [labeled]
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset name (e.g., princeton-nlp/SWE-bench_Verified)'
        required: true
        default: 'princeton-nlp/SWE-bench_Verified'
        type: string
      split:
        description: 'Dataset split (e.g., test, dev)'
        required: true
        default: 'test'
        type: string
      max-workers:
        description: 'Number of concurrent builds'
        required: false
        default: '32'
        type: string
      n-limit:
        description: 'Limit number of images to build (for testing). Leave blank for no limit.'
        required: false
        default: ''
        type: string
      sdk-commit:
        description: 'Software Agent SDK commit/ref to use. Leave blank to use submodule default.'
        required: false
        default: ''
        type: string
  workflow_call:
    inputs:
      dataset:
        description: 'Dataset name (e.g., princeton-nlp/SWE-bench_Verified)'
        required: true
        type: string
      split:
        description: 'Dataset split (e.g., test, dev)'
        required: true
        type: string
      max-workers:
        description: 'Number of concurrent builds'
        required: false
        default: '32'
        type: string
      n-limit:
        description: 'Limit number of images to build (for testing). Leave blank for no limit.'
        required: false
        default: ''
        type: string
      sdk-commit:
        description: 'Software Agent SDK commit/ref to use. Leave blank to use submodule default.'
        required: false
        default: ''
        type: string
    outputs:
      images_built:
        description: 'Number of images successfully built'
        value: ${{ jobs.build-and-push.outputs.images_built }}
      sdk_commit:
        description: 'Actual SDK commit used for the build'
        value: ${{ jobs.build-and-push.outputs.sdk_commit }}
      image_base_name:
        description: 'Base name of the built images'
        value: ${{ jobs.build-and-push.outputs.image_base_name }}

# Reasonable defaults for automatic (push) runs; workflow_dispatch can override these.
env:
  DATASET: princeton-nlp/SWE-bench_Verified
  SPLIT: test
  MAX_WORKERS: '32'
  N_LIMIT: '500'

concurrency:
  group: build-swe-bench-${{ github.ref }}
  cancel-in-progress: false

jobs:
  build-and-push:
    if: >
      github.event_name == 'workflow_dispatch' ||
      github.event_name == 'workflow_call' ||
      (github.event_name == 'pull_request_target' &&
       (github.event.label.name == 'build-swebench' ||
        github.event.label.name == 'build-swebench-50' ||
        github.event.label.name == 'build-swebench-200'))

    runs-on:
      labels: blacksmith-32vcpu-ubuntu-2204

    # Allow pushing to GHCR and commenting on issues
    permissions:
      contents: read
      packages: write
      issues: write

    outputs:
      images_built: ${{ steps.build-summary.outputs.images_built }}
      sdk_commit: ${{ steps.sdk-info.outputs.sdk_commit }}
      image_base_name: ${{ steps.build-summary.outputs.image_base_name }}

    steps:
      - uses: actions/checkout@v4
        with:
          repository: OpenHands/benchmarks
          ref: ${{ github.event_name == 'pull_request_target' && github.event.pull_request.head.sha || github.ref }}
          submodules: recursive

      # If this was a manual dispatch or workflow_call, override defaults with provided inputs.
      - name: Apply workflow_dispatch overrides (if any)
        if: ${{ github.event_name == 'workflow_dispatch' || github.event_name == 'workflow_call' }}
        run: |
          if [ -n "${{ inputs.dataset }}" ]; then echo "DATASET=${{ inputs.dataset }}" >> "$GITHUB_ENV"; fi
          if [ -n "${{ inputs.split }}" ]; then echo "SPLIT=${{ inputs.split }}" >> "$GITHUB_ENV"; fi
          if [ -n "${{ inputs.max-workers }}" ]; then echo "MAX_WORKERS=${{ inputs.max-workers }}" >> "$GITHUB_ENV"; fi
          # Empty string means "no limit"
          if [ -n "${{ inputs.n-limit }}" ]; then echo "N_LIMIT=${{ inputs.n-limit }}" >> "$GITHUB_ENV"; else echo "N_LIMIT=" >> "$GITHUB_ENV"; fi

      # Set N_LIMIT based on the label that triggered the workflow
      - name: Set N_LIMIT based on label
        if: ${{ github.event_name == 'pull_request_target' }}
        run: |
          LABEL_NAME="${{ github.event.label.name }}"
          if [ "$LABEL_NAME" = "build-swebench-50" ]; then
            echo "N_LIMIT=50" >> "$GITHUB_ENV"
            echo "Building 50 images based on label: build-swebench-50"
          elif [ "$LABEL_NAME" = "build-swebench-200" ]; then
            echo "N_LIMIT=200" >> "$GITHUB_ENV"
            echo "Building 200 images based on label: build-swebench-200"
          elif [ "$LABEL_NAME" = "build-swebench" ]; then
            echo "N_LIMIT=" >> "$GITHUB_ENV"
            echo "Building all images based on label: build-swebench"
          fi

      # Update SDK submodule to specific commit if provided
      # Must run BEFORE install dependencies so git submodule update works correctly
      - name: Update SDK submodule
        if: ${{ (github.event_name == 'workflow_dispatch' || github.event_name == 'workflow_call') && inputs.sdk-commit != '' }}
        run: |
          cd vendor/software-agent-sdk
          git fetch origin ${{ inputs.sdk-commit }}
          git checkout FETCH_HEAD
          SDK_SHA=$(git rev-parse HEAD)
          cd ../..
          # Stage the submodule reference update so make build uses it
          git add vendor/software-agent-sdk
          echo "Updated SDK submodule to $SDK_SHA (from ${{ inputs.sdk-commit }})"

      - name: Capture SDK info
        id: sdk-info
        run: |
          SDK_SHA=$(git submodule status vendor/software-agent-sdk | awk '{print $1}' | sed 's/^[+-]//')
          echo "sdk_commit=$SDK_SHA" >> "$GITHUB_OUTPUT"
          echo "Using SDK commit: $SDK_SHA"

      - name: Set up Docker Buildx with Blacksmith
        uses: useblacksmith/setup-docker-builder@v1
        with:
          nofallback: true
          github-token: ${{ secrets.GITHUB_TOKEN }}
          skip-integrity-check: true

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true

      - name: Install dependencies
        run: |
          make build

      - name: Build and push SWE-Bench images
        run: |
          set -euo pipefail

          CMD="uv run benchmarks/swe_bench/build_images.py \
            --dataset '${DATASET}' \
            --split '${SPLIT}' \
            --image ghcr.io/openhands/eval-agent-server \
            --push \
            --max-workers '${MAX_WORKERS}'"

          # Only include --n-limit if provided (non-empty)
          if [ -n "${N_LIMIT}" ]; then
            CMD="$CMD --n-limit '${N_LIMIT}'"
          fi

          echo "Running: $CMD"
          eval "$CMD"
        env:
          DOCKER_BUILDKIT: 1
          BUILDKIT_PROGRESS: plain

      - name: Capture build summary
        id: build-summary
        if: always()
        run: |
          # Find all manifest.jsonl files
          MANIFEST_FILES=$(find builds -name "manifest.jsonl" -type f 2>/dev/null || echo "")
          
          if [ -z "$MANIFEST_FILES" ]; then
            echo "No manifest.jsonl files found"
            echo "images_built=0" >> "$GITHUB_OUTPUT"
            echo "image_base_name=ghcr.io/openhands/eval-agent-server" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          
          # Count successful builds
          SUCCESSES=$(cat $MANIFEST_FILES 2>/dev/null | python -c "
          import sys
          import json
          count = 0
          for line in sys.stdin:
              data = json.loads(line.strip())
              if data.get('error') is None and len(data.get('tags', [])) > 0:
                  count += 1
          print(count)
          ")
          
          echo "images_built=$SUCCESSES" >> "$GITHUB_OUTPUT"
          echo "image_base_name=ghcr.io/openhands/eval-agent-server" >> "$GITHUB_OUTPUT"
          echo "Successfully built $SUCCESSES images"

      - name: Archive build logs
        if: always()
        run: |
          if [ -d builds ]; then
            # Create tar archive to avoid filename restrictions (colons, etc.)
            tar -czf build-logs.tar.gz builds/
            echo "Build logs archived successfully"
          else
            echo "No builds directory found"
          fi

      - name: Upload build logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: build-logs-${{ github.run_id }}
          path: build-logs.tar.gz
          retention-days: 7
          if-no-files-found: warn

      - name: Display build summary
        if: always()
        run: |
          # Find all manifest.jsonl files
          MANIFEST_FILES=$(find builds -name "manifest.jsonl" -type f 2>/dev/null)
          
          if [ -z "$MANIFEST_FILES" ]; then
            echo "No manifest.jsonl files found"
            exit 0
          fi
          
          # Generate summary from manifest files
          echo "## Build Summary" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          
          # Count successes and failures
          TOTAL=$(cat $MANIFEST_FILES 2>/dev/null | wc -l)
          SUCCESSES=$(cat $MANIFEST_FILES 2>/dev/null | python -c "
          import sys
          import json
          count = 0
          for line in sys.stdin:
              data = json.loads(line.strip())
              if data.get('error') is None and len(data.get('tags', [])) > 0:
                  count += 1
          print(count)
          ")
          FAILURES=$((TOTAL - SUCCESSES))
          
          echo "**Total Images:** $TOTAL" >> "$GITHUB_STEP_SUMMARY"
          echo "**Successful Builds:** ✅ $SUCCESSES" >> "$GITHUB_STEP_SUMMARY"
          echo "**Failed Builds:** ❌ $FAILURES" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          
          # Show failed builds if any
          if [ "$FAILURES" -gt 0 ]; then
            echo "### Failed Builds" >> "$GITHUB_STEP_SUMMARY"
            echo "" >> "$GITHUB_STEP_SUMMARY"
            cat $MANIFEST_FILES | python -c "
          import sys
          import json
          for line in sys.stdin:
              data = json.loads(line.strip())
              if data.get('error') is not None or len(data.get('tags', [])) == 0:
                  print(f\"- \\\`{data.get('base_image', 'unknown')}\\\`: {data.get('error', 'No tags generated')}\")
          " >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Comment on tracker issue
        if: success()
        run: |
          # Get SDK version from submodule
          SDK_SHA=$(git submodule status vendor/software-agent-sdk | awk '{print $1}' | sed 's/^[+-]//')
          
          # Find all manifest.jsonl files
          MANIFEST_FILES=$(find builds -name "manifest.jsonl" -type f 2>/dev/null)
          
          if [ -z "$MANIFEST_FILES" ]; then
            echo "No manifest.jsonl files found in builds directory"
            echo "Build may have completed but produced no images"
            exit 0
          fi
          
          # Count total images built
          TOTAL_IMAGES=$(cat $MANIFEST_FILES 2>/dev/null | wc -l)
          
          if [ "$TOTAL_IMAGES" -eq 0 ]; then
            echo "No images found in manifest files"
            echo "Skipping comment as there are no built images to report"
            exit 0
          fi
          
          # Extract all tags and format them as a markdown list (one tag per image)
          TAGS=$(cat $MANIFEST_FILES | python -c "
          import sys
          import json
          for line in sys.stdin:
              data = json.loads(line.strip())
              if data.get('tags') and len(data['tags']) > 0:
                  # Only show the first tag per image to reduce clutter
                  print(f'- \`{data[\"tags\"][0]}\`')
          ")
          
          # Determine how the workflow was triggered
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            TRIGGER="Manual trigger (workflow_dispatch)"
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            TRIGGER="Pull request [#${{ github.event.pull_request.number }}](${{ github.event.pull_request.html_url }})"
          else
            TRIGGER="${{ github.event_name }}"
          fi
          
          # Create the comment body
          COMMENT_BODY=$(cat <<EOF
          ## Build Complete ✅

          **Dataset:** \`${DATASET}\`
          **Split:** \`${SPLIT}\`
          **SDK Version:** [\`${SDK_SHA:0:7}\`](https://github.com/OpenHands/software-agent-sdk/commit/${SDK_SHA})
          **Workflow Run:** [#${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          **Triggered by:** ${TRIGGER}

          <details>
          <summary>Built Tags (${TOTAL_IMAGES} images)</summary>

          ${TAGS}

          </details>
          EOF
          )
          
          # Post comment to issue #81
          curl -L -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "${{ github.api_url }}/repos/${{ github.repository }}/issues/81/comments" \
            -d "$(jq -n --arg body "$COMMENT_BODY" '{body: $body}')"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
