{"kind": "ObservationEvent", "id": "dd28e7cf-2a77-4abf-b662-2b1288d836b1", "timestamp": "2025-09-25T11:25:08.518761", "source": "environment", "tool_name": "str_replace_editor", "tool_call_id": "toolu_01AbV4xxJzAm8UJXuw1z2xCF", "observation": {"kind": "StrReplaceEditorObservation", "command": "str_replace", "output": "The file /tmp/tmpfe5scn8o/astropy/astropy/wcs/wcsapi/wrappers/sliced_wcs.py has been edited. Here's the result of running `cat -n` on a snippet of /tmp/tmpfe5scn8o/astropy/astropy/wcs/wcsapi/wrappers/sliced_wcs.py:\n   242\t\n   243\t        return world_arrays\n   244\t\n   245\t    def world_to_pixel_values(self, *world_arrays):\n   246\t        world_arrays = tuple(map(np.asanyarray, world_arrays))\n   247\t        \n   248\t        # For dropped world dimensions, we need to calculate the correct world coordinate\n   249\t        # values based on the sliced pixel position, not use a hardcoded value.\n   250\t        # We do this by first doing a preliminary transformation to get the world coordinates\n   251\t        # at the center of the kept pixel dimensions, then use those for the dropped dimensions.\n   252\t        \n   253\t        # Get the shape of the input arrays for broadcasting\n   254\t        input_shape = np.broadcast_arrays(*world_arrays)[0].shape\n   255\t        \n   256\t        # Create dummy pixel coordinates at the center of each kept dimension\n   257\t        dummy_pixel_coords = []\n   258\t        for ipix in self._pixel_keep:\n   259\t            # Use 0 as a reasonable default pixel coordinate\n   260\t            dummy_pixel_coords.append(np.zeros(input_shape))\n   261\t        \n   262\t        # Get world coordinates for all dimensions at these dummy pixel positions\n   263\t        dummy_world_coords = self._pixel_to_world_values_all(*dummy_pixel_coords)\n   264\t        \n   265\t        world_arrays_new = []\n   266\t        iworld_curr = -1\n   267\t        for iworld in range(self._wcs.world_n_dim):\n   268\t            if iworld in self._world_keep:\n   269\t                iworld_curr += 1\n   270\t                world_arrays_new.append(world_arrays[iworld_curr])\n   271\t            else:\n   272\t                # Use the world coordinate from the dummy transformation for dropped dimensions\n   273\t                world_arrays_new.append(dummy_world_coords[iworld])\n   274\t\n   275\t        world_arrays_new = np.broadcast_arrays(*world_arrays_new)\n   276\t        pixel_arrays = list(self._wcs.world_to_pixel_values(*world_arrays_new))\n   277\t\n   278\t        for ipixel in range(self._wcs.pixel_n_dim):\n   279\t            if isinstance(self._slices_pixel[ipixel], slice) and self._slices_pixel[ipixel].start is not None:\n   280\t                pixel_arrays[ipixel] -= self._slices_pixel[ipixel].start\n   281\t\nReview the changes and make sure they are as expected. Edit the file again if necessary.", "path": "/tmp/tmpfe5scn8o/astropy/astropy/wcs/wcsapi/wrappers/sliced_wcs.py", "prev_exist": true, "old_content": "import numbers\nfrom collections import defaultdict\n\nimport numpy as np\n\nfrom astropy.utils import isiterable\nfrom astropy.utils.decorators import lazyproperty\n\nfrom ..low_level_api import BaseLowLevelWCS\nfrom .base import BaseWCSWrapper\n\n__all__ = ['sanitize_slices', 'SlicedLowLevelWCS']\n\n\ndef sanitize_slices(slices, ndim):\n    \"\"\"\n    Given a slice as input sanitise it to an easier to parse format.format\n\n    This function returns a list ``ndim`` long containing slice objects (or ints).\n    \"\"\"\n\n    if not isinstance(slices, (tuple, list)):  # We just have a single int\n        slices = (slices,)\n\n    if len(slices) > ndim:\n        raise ValueError(\n            f\"The dimensionality of the specified slice {slices} can not be greater \"\n            f\"than the dimensionality ({ndim}) of the wcs.\")\n\n    if any(isiterable(s) for s in slices):\n        raise IndexError(\"This slice is invalid, only integer or range slices are supported.\")\n\n    slices = list(slices)\n\n    if Ellipsis in slices:\n        if slices.count(Ellipsis) > 1:\n            raise IndexError(\"an index can only have a single ellipsis ('...')\")\n\n        # Replace the Ellipsis with the correct number of slice(None)s\n        e_ind = slices.index(Ellipsis)\n        slices.remove(Ellipsis)\n        n_e = ndim - len(slices)\n        for i in range(n_e):\n            ind = e_ind + i\n            slices.insert(ind, slice(None))\n\n    for i in range(ndim):\n        if i < len(slices):\n            slc = slices[i]\n            if isinstance(slc, slice):\n                if slc.step and slc.step != 1:\n                    raise IndexError(\"Slicing WCS with a step is not supported.\")\n            elif not isinstance(slc, numbers.Integral):\n                raise IndexError(\"Only integer or range slices are accepted.\")\n        else:\n            slices.append(slice(None))\n\n    return slices\n\n\ndef combine_slices(slice1, slice2):\n    \"\"\"\n    Given two slices that can be applied to a 1-d array, find the resulting\n    slice that corresponds to the combination of both slices. We assume that\n    slice2 can be an integer, but slice1 cannot.\n    \"\"\"\n\n    if isinstance(slice1, slice) and slice1.step is not None:\n        raise ValueError('Only slices with steps of 1 are supported')\n\n    if isinstance(slice2, slice) and slice2.step is not None:\n        raise ValueError('Only slices with steps of 1 are supported')\n\n    if isinstance(slice2, numbers.Integral):\n        if slice1.start is None:\n            return slice2\n        else:\n            return slice2 + slice1.start\n\n    if slice1.start is None:\n        if slice1.stop is None:\n            return slice2\n        else:\n            if slice2.stop is None:\n                return slice(slice2.start, slice1.stop)\n            else:\n                return slice(slice2.start, min(slice1.stop, slice2.stop))\n    else:\n        if slice2.start is None:\n            start = slice1.start\n        else:\n            start = slice1.start + slice2.start\n        if slice2.stop is None:\n            stop = slice1.stop\n        else:\n            if slice1.start is None:\n                stop = slice2.stop\n            else:\n                stop = slice2.stop + slice1.start\n            if slice1.stop is not None:\n                stop = min(slice1.stop, stop)\n    return slice(start, stop)\n\n\nclass SlicedLowLevelWCS(BaseWCSWrapper):\n    \"\"\"\n    A Low Level WCS wrapper which applies an array slice to a WCS.\n\n    This class does not modify the underlying WCS object and can therefore drop\n    coupled dimensions as it stores which pixel and world dimensions have been\n    sliced out (or modified) in the underlying WCS and returns the modified\n    results on all the Low Level WCS methods.\n\n    Parameters\n    ----------\n    wcs : `~astropy.wcs.wcsapi.BaseLowLevelWCS`\n        The WCS to slice.\n    slices : `slice` or `tuple` or `int`\n        A valid array slice to apply to the WCS.\n\n    \"\"\"\n    def __init__(self, wcs, slices):\n\n        slices = sanitize_slices(slices, wcs.pixel_n_dim)\n\n        if isinstance(wcs, SlicedLowLevelWCS):\n            # Here we combine the current slices with the previous slices\n            # to avoid ending up with many nested WCSes\n            self._wcs = wcs._wcs\n            slices_original = wcs._slices_array.copy()\n            for ipixel in range(wcs.pixel_n_dim):\n                ipixel_orig = wcs._wcs.pixel_n_dim - 1 - wcs._pixel_keep[ipixel]\n                ipixel_new = wcs.pixel_n_dim - 1 - ipixel\n                slices_original[ipixel_orig] = combine_slices(slices_original[ipixel_orig],\n                                                              slices[ipixel_new])\n            self._slices_array = slices_original\n        else:\n            self._wcs = wcs\n            self._slices_array = slices\n\n        self._slices_pixel = self._slices_array[::-1]\n\n        # figure out which pixel dimensions have been kept, then use axis correlation\n        # matrix to figure out which world dims are kept\n        self._pixel_keep = np.nonzero([not isinstance(self._slices_pixel[ip], numbers.Integral)\n                                       for ip in range(self._wcs.pixel_n_dim)])[0]\n\n        # axis_correlation_matrix[world, pixel]\n        self._world_keep = np.nonzero(\n            self._wcs.axis_correlation_matrix[:, self._pixel_keep].any(axis=1))[0]\n\n        if len(self._pixel_keep) == 0 or len(self._world_keep) == 0:\n            raise ValueError(\"Cannot slice WCS: the resulting WCS should have \"\n                             \"at least one pixel and one world dimension.\")\n\n    @lazyproperty\n    def dropped_world_dimensions(self):\n        \"\"\"\n        Information describing the dropped world dimensions.\n        \"\"\"\n        world_coords = self._pixel_to_world_values_all(*[0]*len(self._pixel_keep))\n        dropped_info = defaultdict(list)\n\n        for i in range(self._wcs.world_n_dim):\n\n            if i in self._world_keep:\n                continue\n\n            if \"world_axis_object_classes\" not in dropped_info:\n                dropped_info[\"world_axis_object_classes\"] = dict()\n\n            wao_classes = self._wcs.world_axis_object_classes\n            wao_components = self._wcs.world_axis_object_components\n\n            dropped_info[\"value\"].append(world_coords[i])\n            dropped_info[\"world_axis_names\"].append(self._wcs.world_axis_names[i])\n            dropped_info[\"world_axis_physical_types\"].append(self._wcs.world_axis_physical_types[i])\n            dropped_info[\"world_axis_units\"].append(self._wcs.world_axis_units[i])\n            dropped_info[\"world_axis_object_components\"].append(wao_components[i])\n            dropped_info[\"world_axis_object_classes\"].update(dict(\n                filter(\n                    lambda x: x[0] == wao_components[i][0], wao_classes.items()\n                )\n            ))\n            dropped_info[\"serialized_classes\"] = self.serialized_classes\n        return dict(dropped_info)\n\n    @property\n    def pixel_n_dim(self):\n        return len(self._pixel_keep)\n\n    @property\n    def world_n_dim(self):\n        return len(self._world_keep)\n\n    @property\n    def world_axis_physical_types(self):\n        return [self._wcs.world_axis_physical_types[i] for i in self._world_keep]\n\n    @property\n    def world_axis_units(self):\n        return [self._wcs.world_axis_units[i] for i in self._world_keep]\n\n    @property\n    def pixel_axis_names(self):\n        return [self._wcs.pixel_axis_names[i] for i in self._pixel_keep]\n\n    @property\n    def world_axis_names(self):\n        return [self._wcs.world_axis_names[i] for i in self._world_keep]\n\n    def _pixel_to_world_values_all(self, *pixel_arrays):\n        pixel_arrays = tuple(map(np.asanyarray, pixel_arrays))\n        pixel_arrays_new = []\n        ipix_curr = -1\n        for ipix in range(self._wcs.pixel_n_dim):\n            if isinstance(self._slices_pixel[ipix], numbers.Integral):\n                pixel_arrays_new.append(self._slices_pixel[ipix])\n            else:\n                ipix_curr += 1\n                if self._slices_pixel[ipix].start is not None:\n                    pixel_arrays_new.append(pixel_arrays[ipix_curr] + self._slices_pixel[ipix].start)\n                else:\n                    pixel_arrays_new.append(pixel_arrays[ipix_curr])\n\n        pixel_arrays_new = np.broadcast_arrays(*pixel_arrays_new)\n        return self._wcs.pixel_to_world_values(*pixel_arrays_new)\n\n    def pixel_to_world_values(self, *pixel_arrays):\n        world_arrays = self._pixel_to_world_values_all(*pixel_arrays)\n\n        # Detect the case of a length 0 array\n        if isinstance(world_arrays, np.ndarray) and not world_arrays.shape:\n            return world_arrays\n\n        if self._wcs.world_n_dim > 1:\n            # Select the dimensions of the original WCS we are keeping.\n            world_arrays = [world_arrays[iw] for iw in self._world_keep]\n            # If there is only one world dimension (after slicing) we shouldn't return a tuple.\n            if self.world_n_dim == 1:\n                world_arrays = world_arrays[0]\n\n        return world_arrays\n\n    def world_to_pixel_values(self, *world_arrays):\n        world_arrays = tuple(map(np.asanyarray, world_arrays))\n        world_arrays_new = []\n        iworld_curr = -1\n        for iworld in range(self._wcs.world_n_dim):\n            if iworld in self._world_keep:\n                iworld_curr += 1\n                world_arrays_new.append(world_arrays[iworld_curr])\n            else:\n                world_arrays_new.append(1.)\n\n        world_arrays_new = np.broadcast_arrays(*world_arrays_new)\n        pixel_arrays = list(self._wcs.world_to_pixel_values(*world_arrays_new))\n\n        for ipixel in range(self._wcs.pixel_n_dim):\n            if isinstance(self._slices_pixel[ipixel], slice) and self._slices_pixel[ipixel].start is not None:\n                pixel_arrays[ipixel] -= self._slices_pixel[ipixel].start\n\n        # Detect the case of a length 0 array\n        if isinstance(pixel_arrays, np.ndarray) and not pixel_arrays.shape:\n            return pixel_arrays\n        pixel = tuple(pixel_arrays[ip] for ip in self._pixel_keep)\n        if self.pixel_n_dim == 1 and self._wcs.pixel_n_dim > 1:\n            pixel = pixel[0]\n        return pixel\n\n    @property\n    def world_axis_object_components(self):\n        return [self._wcs.world_axis_object_components[idx] for idx in self._world_keep]\n\n    @property\n    def world_axis_object_classes(self):\n        keys_keep = [item[0] for item in self.world_axis_object_components]\n        return dict([item for item in self._wcs.world_axis_object_classes.items() if item[0] in keys_keep])\n\n    @property\n    def array_shape(self):\n        if self._wcs.array_shape:\n            return np.broadcast_to(0, self._wcs.array_shape)[tuple(self._slices_array)].shape\n\n    @property\n    def pixel_shape(self):\n        if self.array_shape:\n            return tuple(self.array_shape[::-1])\n\n    @property\n    def pixel_bounds(self):\n        if self._wcs.pixel_bounds is None:\n            return\n\n        bounds = []\n        for idx in self._pixel_keep:\n            if self._slices_pixel[idx].start is None:\n                bounds.append(self._wcs.pixel_bounds[idx])\n            else:\n                imin, imax = self._wcs.pixel_bounds[idx]\n                start = self._slices_pixel[idx].start\n                bounds.append((imin - start, imax - start))\n\n        return tuple(bounds)\n\n    @property\n    def axis_correlation_matrix(self):\n        return self._wcs.axis_correlation_matrix[self._world_keep][:, self._pixel_keep]\n", "new_content": "import numbers\nfrom collections import defaultdict\n\nimport numpy as np\n\nfrom astropy.utils import isiterable\nfrom astropy.utils.decorators import lazyproperty\n\nfrom ..low_level_api import BaseLowLevelWCS\nfrom .base import BaseWCSWrapper\n\n__all__ = ['sanitize_slices', 'SlicedLowLevelWCS']\n\n\ndef sanitize_slices(slices, ndim):\n    \"\"\"\n    Given a slice as input sanitise it to an easier to parse format.format\n\n    This function returns a list ``ndim`` long containing slice objects (or ints).\n    \"\"\"\n\n    if not isinstance(slices, (tuple, list)):  # We just have a single int\n        slices = (slices,)\n\n    if len(slices) > ndim:\n        raise ValueError(\n            f\"The dimensionality of the specified slice {slices} can not be greater \"\n            f\"than the dimensionality ({ndim}) of the wcs.\")\n\n    if any(isiterable(s) for s in slices):\n        raise IndexError(\"This slice is invalid, only integer or range slices are supported.\")\n\n    slices = list(slices)\n\n    if Ellipsis in slices:\n        if slices.count(Ellipsis) > 1:\n            raise IndexError(\"an index can only have a single ellipsis ('...')\")\n\n        # Replace the Ellipsis with the correct number of slice(None)s\n        e_ind = slices.index(Ellipsis)\n        slices.remove(Ellipsis)\n        n_e = ndim - len(slices)\n        for i in range(n_e):\n            ind = e_ind + i\n            slices.insert(ind, slice(None))\n\n    for i in range(ndim):\n        if i < len(slices):\n            slc = slices[i]\n            if isinstance(slc, slice):\n                if slc.step and slc.step != 1:\n                    raise IndexError(\"Slicing WCS with a step is not supported.\")\n            elif not isinstance(slc, numbers.Integral):\n                raise IndexError(\"Only integer or range slices are accepted.\")\n        else:\n            slices.append(slice(None))\n\n    return slices\n\n\ndef combine_slices(slice1, slice2):\n    \"\"\"\n    Given two slices that can be applied to a 1-d array, find the resulting\n    slice that corresponds to the combination of both slices. We assume that\n    slice2 can be an integer, but slice1 cannot.\n    \"\"\"\n\n    if isinstance(slice1, slice) and slice1.step is not None:\n        raise ValueError('Only slices with steps of 1 are supported')\n\n    if isinstance(slice2, slice) and slice2.step is not None:\n        raise ValueError('Only slices with steps of 1 are supported')\n\n    if isinstance(slice2, numbers.Integral):\n        if slice1.start is None:\n            return slice2\n        else:\n            return slice2 + slice1.start\n\n    if slice1.start is None:\n        if slice1.stop is None:\n            return slice2\n        else:\n            if slice2.stop is None:\n                return slice(slice2.start, slice1.stop)\n            else:\n                return slice(slice2.start, min(slice1.stop, slice2.stop))\n    else:\n        if slice2.start is None:\n            start = slice1.start\n        else:\n            start = slice1.start + slice2.start\n        if slice2.stop is None:\n            stop = slice1.stop\n        else:\n            if slice1.start is None:\n                stop = slice2.stop\n            else:\n                stop = slice2.stop + slice1.start\n            if slice1.stop is not None:\n                stop = min(slice1.stop, stop)\n    return slice(start, stop)\n\n\nclass SlicedLowLevelWCS(BaseWCSWrapper):\n    \"\"\"\n    A Low Level WCS wrapper which applies an array slice to a WCS.\n\n    This class does not modify the underlying WCS object and can therefore drop\n    coupled dimensions as it stores which pixel and world dimensions have been\n    sliced out (or modified) in the underlying WCS and returns the modified\n    results on all the Low Level WCS methods.\n\n    Parameters\n    ----------\n    wcs : `~astropy.wcs.wcsapi.BaseLowLevelWCS`\n        The WCS to slice.\n    slices : `slice` or `tuple` or `int`\n        A valid array slice to apply to the WCS.\n\n    \"\"\"\n    def __init__(self, wcs, slices):\n\n        slices = sanitize_slices(slices, wcs.pixel_n_dim)\n\n        if isinstance(wcs, SlicedLowLevelWCS):\n            # Here we combine the current slices with the previous slices\n            # to avoid ending up with many nested WCSes\n            self._wcs = wcs._wcs\n            slices_original = wcs._slices_array.copy()\n            for ipixel in range(wcs.pixel_n_dim):\n                ipixel_orig = wcs._wcs.pixel_n_dim - 1 - wcs._pixel_keep[ipixel]\n                ipixel_new = wcs.pixel_n_dim - 1 - ipixel\n                slices_original[ipixel_orig] = combine_slices(slices_original[ipixel_orig],\n                                                              slices[ipixel_new])\n            self._slices_array = slices_original\n        else:\n            self._wcs = wcs\n            self._slices_array = slices\n\n        self._slices_pixel = self._slices_array[::-1]\n\n        # figure out which pixel dimensions have been kept, then use axis correlation\n        # matrix to figure out which world dims are kept\n        self._pixel_keep = np.nonzero([not isinstance(self._slices_pixel[ip], numbers.Integral)\n                                       for ip in range(self._wcs.pixel_n_dim)])[0]\n\n        # axis_correlation_matrix[world, pixel]\n        self._world_keep = np.nonzero(\n            self._wcs.axis_correlation_matrix[:, self._pixel_keep].any(axis=1))[0]\n\n        if len(self._pixel_keep) == 0 or len(self._world_keep) == 0:\n            raise ValueError(\"Cannot slice WCS: the resulting WCS should have \"\n                             \"at least one pixel and one world dimension.\")\n\n    @lazyproperty\n    def dropped_world_dimensions(self):\n        \"\"\"\n        Information describing the dropped world dimensions.\n        \"\"\"\n        world_coords = self._pixel_to_world_values_all(*[0]*len(self._pixel_keep))\n        dropped_info = defaultdict(list)\n\n        for i in range(self._wcs.world_n_dim):\n\n            if i in self._world_keep:\n                continue\n\n            if \"world_axis_object_classes\" not in dropped_info:\n                dropped_info[\"world_axis_object_classes\"] = dict()\n\n            wao_classes = self._wcs.world_axis_object_classes\n            wao_components = self._wcs.world_axis_object_components\n\n            dropped_info[\"value\"].append(world_coords[i])\n            dropped_info[\"world_axis_names\"].append(self._wcs.world_axis_names[i])\n            dropped_info[\"world_axis_physical_types\"].append(self._wcs.world_axis_physical_types[i])\n            dropped_info[\"world_axis_units\"].append(self._wcs.world_axis_units[i])\n            dropped_info[\"world_axis_object_components\"].append(wao_components[i])\n            dropped_info[\"world_axis_object_classes\"].update(dict(\n                filter(\n                    lambda x: x[0] == wao_components[i][0], wao_classes.items()\n                )\n            ))\n            dropped_info[\"serialized_classes\"] = self.serialized_classes\n        return dict(dropped_info)\n\n    @property\n    def pixel_n_dim(self):\n        return len(self._pixel_keep)\n\n    @property\n    def world_n_dim(self):\n        return len(self._world_keep)\n\n    @property\n    def world_axis_physical_types(self):\n        return [self._wcs.world_axis_physical_types[i] for i in self._world_keep]\n\n    @property\n    def world_axis_units(self):\n        return [self._wcs.world_axis_units[i] for i in self._world_keep]\n\n    @property\n    def pixel_axis_names(self):\n        return [self._wcs.pixel_axis_names[i] for i in self._pixel_keep]\n\n    @property\n    def world_axis_names(self):\n        return [self._wcs.world_axis_names[i] for i in self._world_keep]\n\n    def _pixel_to_world_values_all(self, *pixel_arrays):\n        pixel_arrays = tuple(map(np.asanyarray, pixel_arrays))\n        pixel_arrays_new = []\n        ipix_curr = -1\n        for ipix in range(self._wcs.pixel_n_dim):\n            if isinstance(self._slices_pixel[ipix], numbers.Integral):\n                pixel_arrays_new.append(self._slices_pixel[ipix])\n            else:\n                ipix_curr += 1\n                if self._slices_pixel[ipix].start is not None:\n                    pixel_arrays_new.append(pixel_arrays[ipix_curr] + self._slices_pixel[ipix].start)\n                else:\n                    pixel_arrays_new.append(pixel_arrays[ipix_curr])\n\n        pixel_arrays_new = np.broadcast_arrays(*pixel_arrays_new)\n        return self._wcs.pixel_to_world_values(*pixel_arrays_new)\n\n    def pixel_to_world_values(self, *pixel_arrays):\n        world_arrays = self._pixel_to_world_values_all(*pixel_arrays)\n\n        # Detect the case of a length 0 array\n        if isinstance(world_arrays, np.ndarray) and not world_arrays.shape:\n            return world_arrays\n\n        if self._wcs.world_n_dim > 1:\n            # Select the dimensions of the original WCS we are keeping.\n            world_arrays = [world_arrays[iw] for iw in self._world_keep]\n            # If there is only one world dimension (after slicing) we shouldn't return a tuple.\n            if self.world_n_dim == 1:\n                world_arrays = world_arrays[0]\n\n        return world_arrays\n\n    def world_to_pixel_values(self, *world_arrays):\n        world_arrays = tuple(map(np.asanyarray, world_arrays))\n        \n        # For dropped world dimensions, we need to calculate the correct world coordinate\n        # values based on the sliced pixel position, not use a hardcoded value.\n        # We do this by first doing a preliminary transformation to get the world coordinates\n        # at the center of the kept pixel dimensions, then use those for the dropped dimensions.\n        \n        # Get the shape of the input arrays for broadcasting\n        input_shape = np.broadcast_arrays(*world_arrays)[0].shape\n        \n        # Create dummy pixel coordinates at the center of each kept dimension\n        dummy_pixel_coords = []\n        for ipix in self._pixel_keep:\n            # Use 0 as a reasonable default pixel coordinate\n            dummy_pixel_coords.append(np.zeros(input_shape))\n        \n        # Get world coordinates for all dimensions at these dummy pixel positions\n        dummy_world_coords = self._pixel_to_world_values_all(*dummy_pixel_coords)\n        \n        world_arrays_new = []\n        iworld_curr = -1\n        for iworld in range(self._wcs.world_n_dim):\n            if iworld in self._world_keep:\n                iworld_curr += 1\n                world_arrays_new.append(world_arrays[iworld_curr])\n            else:\n                # Use the world coordinate from the dummy transformation for dropped dimensions\n                world_arrays_new.append(dummy_world_coords[iworld])\n\n        world_arrays_new = np.broadcast_arrays(*world_arrays_new)\n        pixel_arrays = list(self._wcs.world_to_pixel_values(*world_arrays_new))\n\n        for ipixel in range(self._wcs.pixel_n_dim):\n            if isinstance(self._slices_pixel[ipixel], slice) and self._slices_pixel[ipixel].start is not None:\n                pixel_arrays[ipixel] -= self._slices_pixel[ipixel].start\n\n        # Detect the case of a length 0 array\n        if isinstance(pixel_arrays, np.ndarray) and not pixel_arrays.shape:\n            return pixel_arrays\n        pixel = tuple(pixel_arrays[ip] for ip in self._pixel_keep)\n        if self.pixel_n_dim == 1 and self._wcs.pixel_n_dim > 1:\n            pixel = pixel[0]\n        return pixel\n\n    @property\n    def world_axis_object_components(self):\n        return [self._wcs.world_axis_object_components[idx] for idx in self._world_keep]\n\n    @property\n    def world_axis_object_classes(self):\n        keys_keep = [item[0] for item in self.world_axis_object_components]\n        return dict([item for item in self._wcs.world_axis_object_classes.items() if item[0] in keys_keep])\n\n    @property\n    def array_shape(self):\n        if self._wcs.array_shape:\n            return np.broadcast_to(0, self._wcs.array_shape)[tuple(self._slices_array)].shape\n\n    @property\n    def pixel_shape(self):\n        if self.array_shape:\n            return tuple(self.array_shape[::-1])\n\n    @property\n    def pixel_bounds(self):\n        if self._wcs.pixel_bounds is None:\n            return\n\n        bounds = []\n        for idx in self._pixel_keep:\n            if self._slices_pixel[idx].start is None:\n                bounds.append(self._wcs.pixel_bounds[idx])\n            else:\n                imin, imax = self._wcs.pixel_bounds[idx]\n                start = self._slices_pixel[idx].start\n                bounds.append((imin - start, imax - start))\n\n        return tuple(bounds)\n\n    @property\n    def axis_correlation_matrix(self):\n        return self._wcs.axis_correlation_matrix[self._world_keep][:, self._pixel_keep]\n"}, "action_id": "7c41c899-c4cb-461d-9371-98e8a188e0f8"}